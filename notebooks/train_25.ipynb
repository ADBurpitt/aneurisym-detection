{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "351fdca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch.amp.grad_scaler import GradScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d114bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import SERIES_DIR, TRAIN_CSV\n",
    "from src import dataloader as dl\n",
    "from src import partition as pt\n",
    "from src import slice_bag as sb\n",
    "from src import baseline_25D as b25d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "979c3901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.baseline_25D' from '/home/aaron/aneurisym-detection/src/baseline_25D.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(dl)\n",
    "reload(pt)\n",
    "reload(sb)\n",
    "reload(b25d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7705ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "\n",
    "# small, reproducible run\n",
    "SEED = 117\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 1      # keep 1 because bags have variable N\n",
    "NUM_WORKERS = 0\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "Z_THRESH_MM = 1.5   # split thin vs thick\n",
    "\n",
    "# 2.5D bag params (must match model k)\n",
    "K = 5\n",
    "STRIDE = 2\n",
    "RESIZE = (224, 224)\n",
    "POOL = \"mean\"       # or \"max\"\n",
    "\n",
    "# quick training on thin only\n",
    "THIN_OUT_SPACING = (1.0, 1.0, 1.0)\n",
    "THIN_PATCH = (96, 192, 192)\n",
    "\n",
    "# optional: thick params (commented in code below)\n",
    "THICK_XY_SPACING = 1.0\n",
    "THICK_PATCH = (16, 192, 192)\n",
    "\n",
    "OUTDIR = Path(\"checkpoints_25D\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ebc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def set_seed(seed: int = 1337):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def extract_targets(sample: Dict, target_cols: List[str]) -> torch.Tensor:\n",
    "    # your dataset already puts \"label\" if present\n",
    "    if \"label\" in sample:\n",
    "        return sample[\"label\"]\n",
    "    # if not present, create zeros (won’t crash, but won’t learn)\n",
    "    return torch.zeros(len(target_cols), dtype=torch.float32)\n",
    "\n",
    "def alt_iter(dl_a, dl_b):\n",
    "    for a,b in zip_longest(dl_a, dl_b, fillvalue=None):\n",
    "        if a is not None: yield a, \"thin\"\n",
    "        if b is not None: yield b, \"thick\"\n",
    "\n",
    "def unpack_sample_from_batch(batch):\n",
    "    # batch_size==1 loaders; keep dict structure but drop B dim\n",
    "    sample = {k: (v[0] if isinstance(v, torch.Tensor) and v.dim() >= 1 and v.size(0) == 1 else v)\n",
    "              for k, v in batch.items()}\n",
    "    if isinstance(sample[\"volume\"], torch.Tensor) and sample[\"volume\"].ndim == 5:\n",
    "        sample[\"volume\"] = sample[\"volume\"][0]  # [1,Z,Y,X]\n",
    "\n",
    "    # unwrap non-tensor singletons (e.g., uid becomes str not [str])\n",
    "    for k, v in list(sample.items()):\n",
    "        if not isinstance(v, torch.Tensor) and isinstance(v, (list, tuple)) and len(v) == 1:\n",
    "            sample[k] = v[0]\n",
    "            \n",
    "    return sample\n",
    "\n",
    "# ----------------------------\n",
    "# One pass: make bag -> forward -> loss\n",
    "# ----------------------------\n",
    "def forward_one(sample: Dict, model: b25d.ResNet25D, device: torch.device, criterion, target_cols: List[str]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    # sample[\"volume\"] is [1,Z,Y,X] float in [0,1]\n",
    "    bag, _centers = sb.make_slice_bag(sample, k=K, stride=STRIDE, resize=RESIZE)\n",
    "    bag = bag.to(device)  # [N, K, H, W]\n",
    "    logits_inst, logits_bag = model(bag)  # [N, C], [1, C]\n",
    "    y = extract_targets(sample, target_cols).to(device)  # [C]\n",
    "    loss = criterion(logits_bag.squeeze(0), y)\n",
    "    return loss, logits_bag.detach().cpu().squeeze(0), y.detach().cpu()\n",
    "\n",
    "# Kaggle weights: 13x for \"Aneurysm Present\", 1x for others (14 total)\n",
    "def weighted_auc_14(target_cols, y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    # y_true,y_pred: [N, C]\n",
    "    aucs = []\n",
    "    for j, name in enumerate(target_cols):\n",
    "        tj = y_true[:, j]\n",
    "        pj = y_pred[:, j]\n",
    "        auc = np.nan\n",
    "        # need at least 2 classes present\n",
    "        if len({0.0,1.0}.intersection(set(tj.tolist()))) == 2 or (np.min(tj)==0 and np.max(tj)==1):\n",
    "            try: auc = roc_auc_score(tj, pj)\n",
    "            except: pass\n",
    "        aucs.append(auc)\n",
    "\n",
    "    weights = np.ones(len(target_cols), dtype=float)\n",
    "    ap_idx = target_cols.index(\"Aneurysm Present\")\n",
    "    weights[ap_idx] = 13.0\n",
    "\n",
    "    # ignore NaN aucs in both numerator and denominator\n",
    "    aucs_arr = np.array(aucs, dtype=float)\n",
    "    mask = ~np.isnan(aucs_arr)\n",
    "    if not np.any(mask): return np.nan\n",
    "    return float(np.sum(aucs_arr[mask] * weights[mask]) / np.sum(weights[mask]))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loader_full(loader, model, device, target_cols):\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "    for batch in loader:\n",
    "        # unpack sample exactly like train\n",
    "        sample = {k: (v[0] if isinstance(v, torch.Tensor) and getattr(v, \"size\", lambda: [1])()[0]==1 else v) for k, v in batch.items()}\n",
    "        if isinstance(sample[\"volume\"], torch.Tensor) and sample[\"volume\"].ndim == 5:\n",
    "            sample[\"volume\"] = sample[\"volume\"][0]\n",
    "        bag, _ = sb.make_slice_bag(sample, k=K, stride=STRIDE, resize=RESIZE)\n",
    "        bag = bag.to(device)\n",
    "        _, logit_bag = model(bag)             # [1,C]\n",
    "        y = extract_targets(sample, target_cols)  # [C]\n",
    "        all_logits.append(torch.sigmoid(logit_bag.squeeze(0)).cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "    y_pred = np.stack(all_logits, 0)\n",
    "    y_true = np.stack(all_targets, 0)\n",
    "    wauc = weighted_auc_14(target_cols, y_true, y_pred)\n",
    "    return wauc\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_val_union(dl_list, model, device, target_cols):\n",
    "    \"\"\"\n",
    "    Evaluate across multiple loaders (e.g., [dl_thin_val, dl_thick_val]).\n",
    "    Deduplicate by UID: if a UID appears multiple times (different spacings),\n",
    "    average its predicted probabilities.\n",
    "    Returns weighted AUC(14) on the UID-averaged predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    pred_map = {}   # uid -> list of [C] preds\n",
    "    targ_map = {}   # uid -> [C] target (assumed identical across duplicates)\n",
    "\n",
    "    for loader in dl_list:\n",
    "        if loader is None:\n",
    "            continue\n",
    "        for batch in loader:\n",
    "            sample = unpack_sample_from_batch(batch)\n",
    "            uid = sample[\"uid\"]\n",
    "            bag, _ = sb.make_slice_bag(sample, k=K, stride=STRIDE, resize=RESIZE)\n",
    "            bag = bag.to(device)\n",
    "            _, logit_bag = model(bag)                 # [1,C]\n",
    "            probs = torch.sigmoid(logit_bag.squeeze(0)).cpu().numpy()  # [C]\n",
    "            y = extract_targets(sample, target_cols).cpu().numpy()      # [C]\n",
    "\n",
    "            pred_map.setdefault(uid, []).append(probs)\n",
    "            targ_map[uid] = y\n",
    "\n",
    "    if not pred_map:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    # UID-level averaging (if seen in multiple loaders)\n",
    "    uids = sorted(pred_map.keys())\n",
    "    y_pred = np.stack([np.mean(pred_map[u], axis=0) for u in uids], axis=0)  # [N,C]\n",
    "    y_true = np.stack([targ_map[u] for u in uids], axis=0)                   # [N,C]\n",
    "\n",
    "    per_label_aucs = []\n",
    "    for j, name in enumerate(target_cols):\n",
    "        yj, pj = y_true[:, j], y_pred[:, j]\n",
    "        aucj = np.nan\n",
    "        if len(np.unique(yj)) > 1:\n",
    "            try:\n",
    "                aucj = roc_auc_score(yj, pj)\n",
    "            except Exception:\n",
    "                pass\n",
    "        per_label_aucs.append((name, aucj))\n",
    "\n",
    "    # Compact print: top-3 / bottom-3 (ignoring NaNs)\n",
    "    valid = [(n,a) for n,a in per_label_aucs if not np.isnan(a)]\n",
    "    valid.sort(key=lambda x: x[1])\n",
    "    if valid:\n",
    "        worst = \", \".join(f\"{n}:{a:.2f}\" for n,a in valid[:3])\n",
    "        best  = \", \".join(f\"{n}:{a:.2f}\" for n,a in valid[-3:])\n",
    "        print(f\"Per-label AUCs — worst: {worst} | best: {best}\")\n",
    "\n",
    "    ap_idx = target_cols.index(\"Aneurysm Present\")\n",
    "    try:\n",
    "        ap_auc = roc_auc_score(y_true[:, ap_idx], y_pred[:, ap_idx]) if len(set(y_true[:, ap_idx])) > 1 else float(\"nan\")\n",
    "    except Exception:\n",
    "        ap_auc = float(\"nan\")\n",
    "        \n",
    "    if not np.isnan(ap_auc):\n",
    "        print(f\"AP AUC (val-union)={ap_auc:.3f}\")\n",
    "\n",
    "\n",
    "    return weighted_auc_14(target_cols, y_true, y_pred)\n",
    "\n",
    "\n",
    "def compute_pos_weight_from_labels(labels_map, uids, cap: float = 50.0, laplace: float = 1.0, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    pos_weight_j = (neg_j + laplace) / (pos_j + laplace), then clipped to [1, cap].\n",
    "    Use laplace=1.0 for stronger smoothing on tiny datasets.\n",
    "    \"\"\"\n",
    "    labels = np.stack([labels_map[u] for u in uids if u in labels_map], axis=0).astype(np.float32)\n",
    "    pos = labels.sum(axis=0)\n",
    "    neg = labels.shape[0] - pos\n",
    "    pw = (neg + laplace) / (pos + laplace)          # Laplace smoothing\n",
    "    pw = np.clip(pw, 1.0, cap)                      # avoid extreme weights\n",
    "    return torch.as_tensor(pw, dtype=torch.float32, device=device)\n",
    "\n",
    "# data split\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Eval loops\n",
    "# ----------------------------\n",
    "def run_epoch(\n",
    "    loader,                         # DataLoader OR a tuple/list of (dl_thin, dl_thick)\n",
    "    model: b25d.ResNet25D,\n",
    "    device,\n",
    "    optimizer,\n",
    "    scaler,\n",
    "    train: bool,\n",
    "    target_cols: List[str],\n",
    "    *,\n",
    "    criterion: nn.Module,          # <-- pass in (e.g., BCEWithLogitsLoss with pos_weight)\n",
    ") -> Tuple[float, float | None]:\n",
    "    \"\"\"\n",
    "    If `loader` is a single DataLoader -> iterate it.\n",
    "    If `loader` is (dl_thin, dl_thick) or [dl_thin, dl_thick] -> alternate via alt_iter.\n",
    "    \"\"\"\n",
    "    model.train(train)\n",
    "    running = 0.0\n",
    "    preds_ap, targs_ap = [], []\n",
    "    idx_ap = target_cols.index(\"Aneurysm Present\")\n",
    "\n",
    "    # choose iterator\n",
    "    if isinstance(loader, (tuple, list)) and len(loader) == 2:\n",
    "        batch_iter = alt_iter(loader[0], loader[1])   # yields (batch, \"thin\"/\"thick\")\n",
    "        num_steps = len(loader[0]) + len(loader[1])\n",
    "        def extract_batch(item): \n",
    "            batch, _kind = item\n",
    "            return batch\n",
    "    else:\n",
    "        batch_iter = loader\n",
    "        num_steps = len(loader)\n",
    "        def extract_batch(item): \n",
    "            return item\n",
    "\n",
    "    for item in batch_iter:\n",
    "        batch = extract_batch(item)\n",
    "        sample = unpack_sample_from_batch(batch)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16, enabled=(device.type == \"cuda\")):\n",
    "                loss, logits_bag_cpu, y_cpu = forward_one(sample, model, device, criterion, target_cols)\n",
    "            # backprop with AMP\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            with torch.no_grad(), torch.autocast(device_type=device.type, dtype=torch.float16, enabled=(device.type == \"cuda\")):\n",
    "                loss, logits_bag_cpu, y_cpu = forward_one(sample, model, device, criterion, target_cols)\n",
    "\n",
    "        running += float(loss.item())\n",
    "        # AP AUC bookkeeping (logits_bag_cpu / y_cpu are already on CPU)\n",
    "        preds_ap.append(torch.sigmoid(torch.as_tensor(logits_bag_cpu[idx_ap])).item())\n",
    "        targs_ap.append(float(y_cpu[idx_ap].item()))\n",
    "\n",
    "    avg_loss = running / max(1, num_steps)\n",
    "    auc_ap = None\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        auc_ap = roc_auc_score(targs_ap, preds_ap) if len(set(targs_ap)) > 1 else None\n",
    "    except Exception:\n",
    "        auc_ap = None\n",
    "    return avg_loss, auc_ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "556471a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "train=7, val=3; AP counts -> train:2.0, val:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/aneurisym-detection/src/partition.py:137: UserWarning: make_loaders: thick split is empty after filtering.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train thin=7 thick=0 | val thin=1 thick=2\n",
      "[Epoch 01] train_loss=0.7227 | train_AUC(AP)=0.300 || val_loss(thin)=0.8856\n",
      "AP AUC (val-union)=1.000\n",
      "weightedAUC(14, val-union)=1.000\n",
      "[Epoch 02] train_loss=0.5591 | train_AUC(AP)=0.500 || val_loss(thin)=0.8075\n",
      "AP AUC (val-union)=0.000\n",
      "weightedAUC(14, val-union)=0.071\n",
      "[Epoch 03] train_loss=0.4250 | train_AUC(AP)=0.700 || val_loss(thin)=0.7558\n",
      "AP AUC (val-union)=1.000\n",
      "weightedAUC(14, val-union)=1.000\n",
      "Done ✅\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# labels map\n",
    "target_cols = list(dl.TARGET_COLS_DEFAULT)\n",
    "labels_map = dl.build_labels_map_from_csv(TRAIN_CSV, target_cols=target_cols)\n",
    "\n",
    "meta = pd.read_csv(TRAIN_CSV, usecols=[\"SeriesInstanceUID\",\"Modality\",\"Aneurysm Present\"])\n",
    "meta[\"SeriesInstanceUID\"] = meta[\"SeriesInstanceUID\"].astype(str)\n",
    "\n",
    "# restrict to UIDs that actually exist under SERIES_DIR (thin or thick)\n",
    "thin_dirs, thick_dirs = pt.split_series_by_z(SERIES_DIR, z_thresh_mm=Z_THRESH_MM)\n",
    "have = {p.name for p in thin_dirs + thick_dirs}\n",
    "meta = meta[meta[\"SeriesInstanceUID\"].isin(have)].reset_index(drop=True)\n",
    "\n",
    "uids = meta[\"SeriesInstanceUID\"].tolist()\n",
    "mods = meta[\"Modality\"].astype(str).tolist()\n",
    "aps  = meta[\"Aneurysm Present\"].astype(int).tolist()\n",
    "\n",
    "train_uids, val_uids = safe_stratified_split(uids, mods, aps, val_frac=0.25, seed=SEED)\n",
    "print(f\"train={len(train_uids)}, val={len(val_uids)}; AP counts -> train:{sum(labels_map[u][-1] for u in train_uids)}, val:{sum(labels_map[u][-1] for u in val_uids)}\")\n",
    "\n",
    "# --- build loaders with your existing function, using uid_filter ---\n",
    "dl_thin_tr, dl_thick_tr, ds_thin_tr, ds_thick_tr = pt.make_loaders(\n",
    "    SERIES_DIR, labels_map,\n",
    "    z_thresh_mm=Z_THRESH_MM,\n",
    "    thin_out=THIN_OUT_SPACING,\n",
    "    thick_xy=THICK_XY_SPACING,\n",
    "    thin_patch=THIN_PATCH,\n",
    "    thick_patch=THICK_PATCH,\n",
    "    batch_size_thin=BATCH_SIZE,\n",
    "    batch_size_thick=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    uid_filter=set(train_uids),\n",
    ")\n",
    "\n",
    "dl_thin_val, dl_thick_val, ds_thin_val, ds_thick_val = pt.make_loaders(\n",
    "    SERIES_DIR, labels_map,\n",
    "    z_thresh_mm=Z_THRESH_MM,\n",
    "    thin_out=THIN_OUT_SPACING,\n",
    "    thick_xy=THICK_XY_SPACING,\n",
    "    thin_patch=THIN_PATCH,\n",
    "    thick_patch=THICK_PATCH,\n",
    "    batch_size_thin=BATCH_SIZE,\n",
    "    batch_size_thick=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    uid_filter=set(val_uids),\n",
    ")\n",
    "\n",
    "# model\n",
    "model = b25d.ResNet25D(num_classes=len(target_cols), k=K, pool=POOL, pretrained=True).to(device)\n",
    "\n",
    "# opt / amp\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
    "\n",
    "pos_weight = compute_pos_weight_from_labels(labels_map, train_uids, cap=50.0, laplace=1.0, device=str(device))\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "print(f\"train thin={len(ds_thin_tr)} thick={len(ds_thick_tr)} | val thin={len(ds_thin_val)} thick={len(ds_thick_val)}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    tr_loss, tr_auc = run_epoch((dl_thin_tr, dl_thick_tr), model, device, optimizer, scaler, True, target_cols, criterion=criterion)\n",
    "    va_loss, va_auc = run_epoch(dl_thin_val, model, device, optimizer, scaler, False, target_cols, criterion=criterion)\n",
    "\n",
    "    msg = f\"[Epoch {epoch:02d}] train_loss={tr_loss:.4f}\"\n",
    "    if tr_auc is not None: msg += f\" | train_AUC(AP)={tr_auc:.3f}\"\n",
    "    msg += f\" || val_loss(thin)={va_loss:.4f}\"\n",
    "    if va_auc is not None: msg += f\" | val_AUC(AP)={va_auc:.3f}\"\n",
    "    print(msg)\n",
    "\n",
    "    # wauc = eval_loader_full(dl_thin_val, model, device, target_cols)\n",
    "    # print(f\"weightedAUC(14, val-thin)={wauc:.3f}\")\n",
    "\n",
    "    wauc = eval_val_union([dl_thin_val, dl_thick_val], model, device, target_cols)\n",
    "    print(f\"weightedAUC(14, val-union)={wauc:.3f}\")\n",
    "\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"config\": {\n",
    "            \"K\": K, \"POOL\": POOL, \"RESIZE\": RESIZE,\n",
    "            \"THIN_OUT_SPACING\": THIN_OUT_SPACING, \"THIN_PATCH\": THIN_PATCH,\n",
    "            \"THICK_XY_SPACING\": THICK_XY_SPACING, \"THICK_PATCH\": THICK_PATCH,\n",
    "            \"STRIDE\": STRIDE, \"target_cols\": target_cols,\n",
    "        },\n",
    "    }, OUTDIR / f\"resnet25d_epoch{epoch:02d}.pt\")\n",
    "\n",
    "print(\"Done ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device: cuda\n",
    "# Thin series: 8 | Thick series: 2\n",
    "# Training on THIN only for now (8 iters/epoch)\n",
    "# [Epoch 01] train_loss=0.6521 | train_AUC(AP)=0.533 || val_loss=0.6259 | val_AUC(AP)=0.733\n",
    "# [Epoch 02] train_loss=0.4617 | train_AUC(AP)=0.733 || val_loss=0.3998 | val_AUC(AP)=0.533\n",
    "# [Epoch 03] train_loss=0.3232 | train_AUC(AP)=0.667 || val_loss=0.3329 | val_AUC(AP)=0.400\n",
    "# Done ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccea7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device: cuda\n",
    "# Thin series: 8 | Thick series: 2\n",
    "# Training on THIN only for now (8 iters/epoch)\n",
    "# [Epoch 01] train_loss=0.6492 | train_AUC(AP)=0.633 || val_loss=0.6287 | val_AUC(AP)=0.733\n",
    "# weightedAUC(14)=0.599\n",
    "# [Epoch 02] train_loss=0.4638 | train_AUC(AP)=0.733 || val_loss=0.5045 | val_AUC(AP)=0.600\n",
    "# weightedAUC(14)=0.601\n",
    "# [Epoch 03] train_loss=0.3269 | train_AUC(AP)=0.333 || val_loss=0.4203 | val_AUC(AP)=0.500\n",
    "# weightedAUC(14)=0.310\n",
    "# Done ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device: cuda\n",
    "# Thin series: 8 | Thick series: 2\n",
    "# Training by alternating THIN and THICK batches\n",
    "# [Epoch 01] train_loss=0.7400 | train_AUC(AP)=0.381 || val_loss(thin)=0.7221 | val_AUC(AP)=0.000\n",
    "# weightedAUC(14, thin)=0.561\n",
    "# [Epoch 02] train_loss=0.5189 | train_AUC(AP)=0.714 || val_loss(thin)=0.5326 | val_AUC(AP)=0.800\n",
    "# weightedAUC(14, thin)=0.327\n",
    "# [Epoch 03] train_loss=0.4395 | train_AUC(AP)=0.238 || val_loss(thin)=0.4649 | val_AUC(AP)=0.600\n",
    "# weightedAUC(14, thin)=0.428\n",
    "# Done ✅"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aneurisym-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
